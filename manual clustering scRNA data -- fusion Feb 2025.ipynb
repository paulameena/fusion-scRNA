{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993062ff-ae6f-41ff-afbb-0dee34bba9d3",
   "metadata": {},
   "source": [
    "## Based on Arda instructions after I tried to do clustering though Kmeans samples\n",
    "\n",
    "Arda: So I think you should not do Kmeans clustering, 1) the umap space is not a good space to do any analysis on just for visualization. For the gene expression space, K-means will not be optimal either due the number of features etc.. So your strategy should be; 1)for over 100(0) iterations: subsample both cells and genes by %90, cluster using leiden clustering with default parameters, keep track of which pair of cells are clustered together. 2) from the 100(0) iterations, calculate the frequency of pairwise occurrence, and do a final hierarchical clustering using silhouette as a metric. 3) Using the identified clusters, create a PAGA graph and subsequently create a UMAP using the PAGA initialization. The third step will give you a nice visualization overlapping with your clusters identified from 1-2\n",
    "This will give you a robust clustering\n",
    "\n",
    "ChatGPT was used for initial code outline but modified to simplify computational usage e.g. through Arda'a idea of doing a dot product of one-hot encoded versions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ab34b6-b699-41c4-9a3c-045aef953b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ece393f-eacf-4939-b716-be4cdd83f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ... Load your AnnData object (adata) ...\n",
    "\n",
    "adata= sc.read_h5ad(\"adata_filtered_combined_feb2025.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd5adb9-9e03-4cf7-b9e6-b89152a865ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_iterations = 100  # Increased iterations for robustness\n",
    "pairwise_cooccurrence = np.zeros((21784, 21784))\n",
    "\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Subsample cells and genes (90%)\n",
    "    cells_to_keep = np.random.choice(adata.obs_names, size=int(0.9 * len(adata.obs_names)), replace=False)\n",
    "    genes_to_keep = np.random.choice(adata.var_names, size=int(0.9 * len(adata.var_names)), replace=False)\n",
    "    adata_subsampled = adata[cells_to_keep, genes_to_keep].copy()\n",
    "\n",
    "    # Leiden clustering (default parameters)\n",
    "    sc.pp.neighbors(adata_subsampled)\n",
    "    sc.tl.leiden(adata_subsampled)\n",
    "\n",
    "    # Track pairwise co-occurrence -- using one hot encoding!!!\n",
    "    test = pd.get_dummies(adata_subsampled.obs['leiden'])\n",
    "    #print(test)\n",
    "    a = np.dot(test,test.T) #dot product counts number of times cells are paired together\n",
    "    #print(a.shape)\n",
    "    #print(a)\n",
    "    pairwise_cooccurrence = pairwise_cooccurrence + a #add to existing counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00284a8d-6390-4eb9-bd5d-6175d545de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Frequency Calculation and Hierarchical Clustering:\n",
    "\n",
    "python\n",
    "Copy\n",
    "# Convert to a distance matrix (1-normalized co-occurrence)\n",
    "cooccurrence_matrix_normalized = pairwise_cooccurrence.values / n_iterations\n",
    "distance_matrix = 1 - cooccurrence_matrix_normalized\n",
    "\n",
    "# Hierarchical clustering using ward linkage (can experiment with other methods)\n",
    "linkage_matrix = linkage(distance_matrix, method='ward')\n",
    "\n",
    "#The silhouette score is not suitable as a metric for hierarchical clustering, since it's a metric to asses cluster quality\n",
    "#You could calculate the silhouette score on the final clusters after hierarchical clustering\n",
    "\n",
    "#You can determine the number of clusters by looking at the dendrogram (see below)\n",
    "#or by using some other metric (e.g. calculating the silhouette score for different numbers of clusters and selecting the one with the best score)\n",
    "dendrogram(linkage_matrix)\n",
    "plt.show()\n",
    "#Cut the dendrogram to get a certain number of clusters\n",
    "cluster_labels = fcluster(linkage_matrix, t=4, criterion='maxclust') #Example: 4 clusters\n",
    "adata.obs['consensus_cluster'] = cluster_labels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
