{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993062ff-ae6f-41ff-afbb-0dee34bba9d3",
   "metadata": {},
   "source": [
    "## Based on Arda instructions after I tried to do clustering though Kmeans samples\n",
    "\n",
    "Arda: So I think you should not do Kmeans clustering, 1) the umap space is not a good space to do any analysis on just for visualization. For the gene expression space, K-means will not be optimal either due the number of features etc.. So your strategy should be; 1)for over 100(0) iterations: subsample both cells and genes by %90, cluster using leiden clustering with default parameters, keep track of which pair of cells are clustered together. 2) from the 100(0) iterations, calculate the frequency of pairwise occurrence, and do a final hierarchical clustering using silhouette as a metric. 3) Using the identified clusters, create a PAGA graph and subsequently create a UMAP using the PAGA initialization. The third step will give you a nice visualization overlapping with your clusters identified from 1-2\n",
    "This will give you a robust clustering\n",
    "\n",
    "ChatGPT was used for initial code outline but modified to simplify computational usage e.g. through Arda'a idea of doing a dot product of one-hot encoded versions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ab34b6-b699-41c4-9a3c-045aef953b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ece393f-eacf-4939-b716-be4cdd83f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ... Load your AnnData object (adata) ...\n",
    "\n",
    "adata= sc.read_h5ad(\"adata_filtered_combined_feb2025.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f803cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_total = len(adata.obs_names)\n",
    "#a= np.array([[0,0]] * num_total) #list of length len(adata.obs_names) with [0,0] at each point\n",
    "#print(a)\n",
    "\n",
    "#test1 = np.dot(a, a.T)\n",
    "#print(test1)\n",
    "#print(test1.shape)\n",
    "\n",
    "#masking may be the answer -- use a mask to take the subset and then negate the mask to grab the original co-occurence values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "abd5adb9-9e03-4cf7-b9e6-b89152a865ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_iterations = 1000  # Increased iterations for robustness\\npairwise_cooccurrence = a= np.zeros((length, length))\\noriginal_list_indices=adata.obs_names.to_list()\\n#print(pairwise_cooccurrence)\\n#print(len(adata.obs_names))\\n\\nfor i in range(n_iterations):\\n    # Subsample cells and genes (90%)\\n    cells_to_keep = np.random.choice(adata.obs_names, size=int(0.9 * len(adata.obs_names)), replace=False)\\n    genes_to_keep = np.random.choice(adata.var_names, size=int(0.9 * len(adata.var_names)), replace=False)\\n    adata_subsampled = adata[cells_to_keep, genes_to_keep].copy()\\n    print(adata_subsampled.obs[\\'leiden\\'])\\n\\n    # Leiden clustering (default parameters)\\n    sc.pp.neighbors(adata_subsampled)\\n    sc.tl.leiden(adata_subsampled)\\n\\n    # Track pairwise co-occurrence -- using one hot encoding!!!\\n    test = pd.get_dummies(adata_subsampled.obs[\\'leiden\\'])\\n    #print(test)\\n    #print(test.index)\\n    a = np.dot(test,test.T) #dot product counts number of times cells are paired together\\n    #a.col_names = \\n    #print(a.shape)\\n    #print(a)\\n    for j,k in itertools.product(range(len(test.index)), range(len(test.index))):\\n        if a[j][k] == 0:\\n             continue     \\n        cell1 = test.index[j]\\n        #print(cell1)\\n        cell2 = test.index[k]\\n        position_j_orig = original_list_indices.index(cell1)\\n        #print(position_j_orig)\\n        position_k_orig = original_list_indices.index(cell2)\\n        #print(position_k_orig)\\n        pairwise_coocurrence_val = pairwise_cooccurrence[position_j_orig][position_k_orig]\\n        pairwise_cooccurrence[position_j_orig][position_k_orig] = pairwise_coocurrence_val + a[j][k]\\n        #print(j)\\n        #print(k)\\n    \\n    print(\"completed run: \" + str(i))\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "n_iterations = 1000  # Increased iterations for robustness\n",
    "pairwise_cooccurrence = a= np.zeros((length, length))\n",
    "original_list_indices=adata.obs_names.to_list()\n",
    "#print(pairwise_cooccurrence)\n",
    "#print(len(adata.obs_names))\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Subsample cells and genes (90%)\n",
    "    cells_to_keep = np.random.choice(adata.obs_names, size=int(0.9 * len(adata.obs_names)), replace=False)\n",
    "    genes_to_keep = np.random.choice(adata.var_names, size=int(0.9 * len(adata.var_names)), replace=False)\n",
    "    adata_subsampled = adata[cells_to_keep, genes_to_keep].copy()\n",
    "    print(adata_subsampled.obs['leiden'])\n",
    "\n",
    "    # Leiden clustering (default parameters)\n",
    "    sc.pp.neighbors(adata_subsampled)\n",
    "    sc.tl.leiden(adata_subsampled)\n",
    "\n",
    "    # Track pairwise co-occurrence -- using one hot encoding!!!\n",
    "    test = pd.get_dummies(adata_subsampled.obs['leiden'])\n",
    "    #print(test)\n",
    "    #print(test.index)\n",
    "    a = np.dot(test,test.T) #dot product counts number of times cells are paired together\n",
    "    #a.col_names = \n",
    "    #print(a.shape)\n",
    "    #print(a)\n",
    "    for j,k in itertools.product(range(len(test.index)), range(len(test.index))):\n",
    "        if a[j][k] == 0:\n",
    "             continue     \n",
    "        cell1 = test.index[j]\n",
    "        #print(cell1)\n",
    "        cell2 = test.index[k]\n",
    "        position_j_orig = original_list_indices.index(cell1)\n",
    "        #print(position_j_orig)\n",
    "        position_k_orig = original_list_indices.index(cell2)\n",
    "        #print(position_k_orig)\n",
    "        pairwise_coocurrence_val = pairwise_cooccurrence[position_j_orig][position_k_orig]\n",
    "        pairwise_cooccurrence[position_j_orig][position_k_orig] = pairwise_coocurrence_val + a[j][k]\n",
    "        #print(j)\n",
    "        #print(k)\n",
    "    \n",
    "    print(\"completed run: \" + str(i))\n",
    "\"\"\"              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a88314",
   "metadata": {},
   "source": [
    "too computationally expensive --> ideas from Arda:\n",
    "\n",
    "--when take random subset, keep track of indices chosen so can take leiden clusters on subset data back to normal dimensions before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7afcebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed run: 0\n",
      "completed run: 1\n",
      "completed run: 2\n",
      "completed run: 3\n",
      "completed run: 4\n",
      "completed run: 5\n",
      "completed run: 6\n",
      "completed run: 7\n",
      "completed run: 8\n",
      "completed run: 9\n",
      "completed run: 10\n",
      "completed run: 11\n",
      "completed run: 12\n",
      "completed run: 13\n",
      "completed run: 14\n",
      "completed run: 15\n",
      "completed run: 16\n",
      "completed run: 17\n",
      "completed run: 18\n",
      "completed run: 19\n",
      "completed run: 20\n",
      "completed run: 21\n",
      "completed run: 22\n",
      "completed run: 23\n",
      "completed run: 24\n",
      "completed run: 25\n",
      "completed run: 26\n",
      "completed run: 27\n",
      "completed run: 28\n",
      "completed run: 29\n",
      "completed run: 30\n",
      "completed run: 31\n",
      "completed run: 32\n",
      "completed run: 33\n",
      "completed run: 34\n",
      "completed run: 35\n",
      "completed run: 36\n",
      "completed run: 37\n",
      "completed run: 38\n",
      "completed run: 39\n",
      "completed run: 40\n",
      "completed run: 41\n",
      "completed run: 42\n",
      "completed run: 43\n",
      "completed run: 44\n",
      "completed run: 45\n",
      "completed run: 46\n",
      "completed run: 47\n",
      "completed run: 48\n",
      "completed run: 49\n",
      "completed run: 50\n",
      "completed run: 51\n",
      "completed run: 52\n",
      "completed run: 53\n",
      "completed run: 54\n",
      "completed run: 55\n",
      "completed run: 56\n",
      "completed run: 57\n",
      "completed run: 58\n",
      "completed run: 59\n",
      "completed run: 60\n",
      "completed run: 61\n",
      "completed run: 62\n",
      "completed run: 63\n",
      "completed run: 64\n",
      "completed run: 65\n",
      "completed run: 66\n",
      "completed run: 67\n",
      "completed run: 68\n",
      "completed run: 69\n",
      "completed run: 70\n",
      "completed run: 71\n",
      "completed run: 72\n",
      "completed run: 73\n",
      "completed run: 74\n",
      "completed run: 75\n",
      "completed run: 76\n",
      "completed run: 77\n",
      "completed run: 78\n",
      "completed run: 79\n",
      "completed run: 80\n",
      "completed run: 81\n",
      "completed run: 82\n",
      "completed run: 83\n",
      "completed run: 84\n",
      "completed run: 85\n",
      "completed run: 86\n",
      "completed run: 87\n",
      "completed run: 88\n",
      "completed run: 89\n",
      "completed run: 90\n",
      "completed run: 91\n",
      "completed run: 92\n",
      "completed run: 93\n",
      "completed run: 94\n",
      "completed run: 95\n",
      "completed run: 96\n",
      "completed run: 97\n",
      "completed run: 98\n",
      "completed run: 99\n",
      "completed run: 100\n",
      "completed run: 101\n",
      "completed run: 102\n",
      "completed run: 103\n",
      "completed run: 104\n",
      "completed run: 105\n",
      "completed run: 106\n",
      "completed run: 107\n",
      "completed run: 108\n",
      "completed run: 109\n",
      "completed run: 110\n",
      "completed run: 111\n",
      "completed run: 112\n",
      "completed run: 113\n",
      "completed run: 114\n",
      "completed run: 115\n",
      "completed run: 116\n",
      "completed run: 117\n",
      "completed run: 118\n",
      "completed run: 119\n",
      "completed run: 120\n",
      "completed run: 121\n",
      "completed run: 122\n",
      "completed run: 123\n",
      "completed run: 124\n",
      "completed run: 125\n",
      "completed run: 126\n",
      "completed run: 127\n",
      "completed run: 128\n",
      "completed run: 129\n",
      "completed run: 130\n",
      "completed run: 131\n"
     ]
    }
   ],
   "source": [
    "#1000 iterations completed on cluster using slurm/sbatch commandline scripy. \n",
    "#See clustering2.py in /mnt/pan/SOM_CCCC_JGS25/shultesp/scRNA...etc/\n",
    "#output was saved to csv as noted below\n",
    "\n",
    "n_iterations = 1000  # Increased iterations for robustness\n",
    "length = len(adata.obs_names)\n",
    "pairwise_cooccurrence = np.zeros((length, length))\n",
    "indices = np.arange(length)\n",
    "#print(pairwise_cooccurrence)\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Subsample cells and genes (90%)\n",
    "    cells_to_keep_indices = np.random.choice(indices, size=int(0.9 * length), replace=False)\n",
    "    genes_to_keep = np.random.choice(adata.var_names, size=int(0.9 * len(adata.var_names)), replace=False)\n",
    "    cells_to_keep = adata.obs_names[cells_to_keep_indices]\n",
    "    adata_subsampled = adata[cells_to_keep, genes_to_keep].copy()\n",
    "\n",
    "    # Leiden clustering (default parameters)\n",
    "    sc.pp.neighbors(adata_subsampled)\n",
    "    sc.tl.leiden(adata_subsampled)\n",
    "    #cluster_counts =pd.group(adata_subsampled.obs[\"leiden\"])\n",
    "    total_cluster_num = adata_subsampled.obs[\"leiden\"].nunique()\n",
    "    #print(cluster_num)\n",
    "    \n",
    "    #expand leiden matrix back to normal dimensions and one-hot-encode\n",
    "    leiden_matrix = np.zeros((length, total_cluster_num))\n",
    "    for j in range(length):\n",
    "        if j not in cells_to_keep_indices:\n",
    "                continue\n",
    "        cell = adata.obs_names[j]\n",
    "        cluster = int(adata_subsampled.obs[\"leiden\"][cell])\n",
    "        leiden_matrix[j][cluster] = 1\n",
    "    #print(leiden_matrix)\n",
    "    \n",
    "    # Track pairwise co-occurrence -- using one hot encoding!!!\n",
    "    #print(test)\n",
    "    #print(test.index)\n",
    "    a = np.dot(leiden_matrix,leiden_matrix.T) #dot product counts number of times cells are paired together across ALL cells\n",
    "    pairwise_cooccurrence = pairwise_cooccurrence + a\n",
    "    #print(pairwise_cooccurrence)\n",
    "    \n",
    "    print(\"completed run: \" + str(i))\n",
    "    #break\n",
    "\n",
    "final_pairwise_df = pd.DataFrame(pairwise_cooccurrence)\n",
    "final_pairwise_df.columns = adata.obs_names\n",
    "final_pairwise_df.index = adata.obs_names\n",
    "\n",
    "final_pairwise_df.to_csv(\"cell_pair_counts.csv\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68adca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load clustering output\n",
    "cell_pair_counts = pd.read_csv(\"/mnt/pan/SOM_CCCC_JGS25/shultesp/scRNAseq-clustering-fusion2025/cell_pair_counts.csv\")\n",
    "cell_pair_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00284a8d-6390-4eb9-bd5d-6175d545de88",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (696632085.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [49], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    2. Frequency Calculation and Hierarchical Clustering:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "2. Frequency Calculation and Hierarchical Clustering:\n",
    "\n",
    "# Convert to a distance matrix (1-normalized co-occurrence)\n",
    "cooccurrence_matrix_normalized = pairwise_cooccurrence.values / n_iterations\n",
    "distance_matrix = 1 - cooccurrence_matrix_normalized\n",
    "\n",
    "# Hierarchical clustering using ward linkage (can experiment with other methods)\n",
    "linkage_matrix = linkage(distance_matrix, method='ward')\n",
    "\n",
    "#The silhouette score is not suitable as a metric for hierarchical clustering, since it's a metric to asses cluster quality\n",
    "#You could calculate the silhouette score on the final clusters after hierarchical clustering\n",
    "\n",
    "#You can determine the number of clusters by looking at the dendrogram (see below)\n",
    "#or by using some other metric (e.g. calculating the silhouette score for different numbers of clusters and selecting the one with the best score)\n",
    "dendrogram(linkage_matrix)\n",
    "plt.show()\n",
    "#Cut the dendrogram to get a certain number of clusters\n",
    "cluster_labels = fcluster(linkage_matrix, t=4, criterion='maxclust') #Example: 4 clusters\n",
    "adata.obs['consensus_cluster'] = cluster_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461d5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
